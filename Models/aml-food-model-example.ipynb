{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food prediction model: L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:06:55.481660Z",
     "iopub.status.busy": "2021-12-13T12:06:55.481223Z",
     "iopub.status.idle": "2021-12-13T12:07:01.245388Z",
     "shell.execute_reply": "2021-12-13T12:07:01.244659Z",
     "shell.execute_reply.started": "2021-12-13T12:06:55.481508Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profide a model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:01.248383Z",
     "iopub.status.busy": "2021-12-13T12:07:01.247835Z",
     "iopub.status.idle": "2021-12-13T12:07:01.251963Z",
     "shell.execute_reply": "2021-12-13T12:07:01.251406Z",
     "shell.execute_reply.started": "2021-12-13T12:07:01.248342Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'J1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:01.253542Z",
     "iopub.status.busy": "2021-12-13T12:07:01.252977Z",
     "iopub.status.idle": "2021-12-13T12:07:03.270164Z",
     "shell.execute_reply": "2021-12-13T12:07:03.269376Z",
     "shell.execute_reply.started": "2021-12-13T12:07:01.253486Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/train-labels/train_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-45ca317a6e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# importing files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_train_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train-labels/train_labels.csv'"
     ]
    }
   ],
   "source": [
    "# file location\n",
    "train_label_path = '../input/train-labels/train_labels.csv'\n",
    "train_image_path = '../input/food-stuff/train_set/train_set/'\n",
    "test_image_path= '../input/test-set-2/test_set'\n",
    "test_results_sample = '../input/sample/sample.csv'\n",
    "\n",
    "# importing files\n",
    "df_train_labels = pd.read_csv(train_label_path, sep=',')\n",
    "df_test_labels = pd.read_csv(test_results_sample, sep=',')\n",
    "\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.272879Z",
     "iopub.status.busy": "2021-12-13T12:07:03.272367Z",
     "iopub.status.idle": "2021-12-13T12:07:03.288902Z",
     "shell.execute_reply": "2021-12-13T12:07:03.288159Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.272838Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.290741Z",
     "iopub.status.busy": "2021-12-13T12:07:03.290296Z",
     "iopub.status.idle": "2021-12-13T12:07:03.294242Z",
     "shell.execute_reply": "2021-12-13T12:07:03.293444Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.290704Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not working on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-procession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.296463Z",
     "iopub.status.busy": "2021-12-13T12:07:03.295921Z",
     "iopub.status.idle": "2021-12-13T12:07:03.627600Z",
     "shell.execute_reply": "2021-12-13T12:07:03.626884Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.296426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding the file paths to the dataframe for train\n",
    "path_list = []\n",
    "for i in range(len(df_train_labels)):\n",
    "    path = '{}'.format(df_train_labels['img_name'][i])\n",
    "    path_list.append(path)\n",
    "\n",
    "    \n",
    "df_train_labels['path'] = path_list\n",
    "df_train_labels['label'] = df_train_labels['label'].astype(str)\n",
    "\n",
    "del path_list\n",
    "\n",
    "# Adding the file paths to the dataframe for test\n",
    "path_list = []\n",
    "for i in range(len(df_test_labels)):\n",
    "    path = '{}'.format(df_test_labels['img_name'][i])\n",
    "    path_list.append(path)\n",
    "\n",
    "    \n",
    "df_test_labels['path'] = path_list\n",
    "df_test_labels['label'] = df_test_labels['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.629217Z",
     "iopub.status.busy": "2021-12-13T12:07:03.628985Z",
     "iopub.status.idle": "2021-12-13T12:07:03.639087Z",
     "shell.execute_reply": "2021-12-13T12:07:03.638289Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.629185Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.641281Z",
     "iopub.status.busy": "2021-12-13T12:07:03.640760Z",
     "iopub.status.idle": "2021-12-13T12:07:03.712443Z",
     "shell.execute_reply": "2021-12-13T12:07:03.711818Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.641245Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "\n",
    "image_train, image_validation = train_test_split(df_train_labels,\n",
    "                                                 test_size=0.3, \n",
    "                                                 random_state=1, \n",
    "                                                 stratify=df_train_labels['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.714034Z",
     "iopub.status.busy": "2021-12-13T12:07:03.713776Z",
     "iopub.status.idle": "2021-12-13T12:07:03.723848Z",
     "shell.execute_reply": "2021-12-13T12:07:03.723183Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.714000Z"
    }
   },
   "outputs": [],
   "source": [
    "image_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:07:03.727642Z",
     "iopub.status.busy": "2021-12-13T12:07:03.726751Z",
     "iopub.status.idle": "2021-12-13T12:08:52.738441Z",
     "shell.execute_reply": "2021-12-13T12:08:52.737716Z",
     "shell.execute_reply.started": "2021-12-13T12:07:03.727603Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting image parameters\n",
    "img_height = 224 \n",
    "img_width = 224\n",
    "image_size = (img_height,img_width)\n",
    "batch_size = 85\n",
    "\n",
    "# defining Generators\n",
    "datagen = ImageDataGenerator()\n",
    "dataval = ImageDataGenerator()\n",
    "test = ImageDataGenerator()\n",
    "\n",
    "# parameters train data\n",
    "train_images = datagen.flow_from_dataframe(\n",
    "    image_train,\n",
    "    directory = train_image_path,\n",
    "    class_mode='categorical',\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    shuffle=True,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#  parameters validation data\n",
    "validation_images = dataval.flow_from_dataframe(\n",
    "    image_validation,\n",
    "    directory = train_image_path,\n",
    "    class_mode='categorical',\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    shuffle=True,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#  parameters test data\n",
    "test_generator = test.flow_from_directory(\n",
    "        test_image_path,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:08:52.740491Z",
     "iopub.status.busy": "2021-12-13T12:08:52.739752Z",
     "iopub.status.idle": "2021-12-13T12:08:54.976103Z",
     "shell.execute_reply": "2021-12-13T12:08:54.975056Z",
     "shell.execute_reply.started": "2021-12-13T12:08:52.740450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of output layers/classes\n",
    "num_classes = 80\n",
    "\n",
    "#Setting the input size\n",
    "input_shape = (img_height,img_width,3)\n",
    "\n",
    "# running dif model\n",
    "model = tf.keras.applications.ResNet50( # change model name !!!!\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=\"avg\",\n",
    "    classes=num_classes)\n",
    "\n",
    "# Specify first layer as non-trainable\n",
    "model.trainable = False\n",
    "inputs = model.input\n",
    "\n",
    "outputs = tf.keras.layers.Dense(80, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# compiling model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:08:54.977609Z",
     "iopub.status.busy": "2021-12-13T12:08:54.977362Z",
     "iopub.status.idle": "2021-12-13T12:08:55.062735Z",
     "shell.execute_reply": "2021-12-13T12:08:55.058553Z",
     "shell.execute_reply.started": "2021-12-13T12:08:54.977576Z"
    }
   },
   "outputs": [],
   "source": [
    "# model overview\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:08:55.064046Z",
     "iopub.status.busy": "2021-12-13T12:08:55.063812Z",
     "iopub.status.idle": "2021-12-13T12:08:55.068256Z",
     "shell.execute_reply": "2021-12-13T12:08:55.067236Z",
     "shell.execute_reply.started": "2021-12-13T12:08:55.064011Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting the location for train results\n",
    "checkpoint_path = 'training_1/cp.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:08:55.069808Z",
     "iopub.status.busy": "2021-12-13T12:08:55.069572Z"
    }
   },
   "outputs": [],
   "source": [
    "# time time\n",
    "%%time\n",
    "# setting the number of training iterations\n",
    "epochs=1\n",
    "\n",
    "# saving substeps\n",
    "chkp = tf.keras.callbacks.ModelCheckpoint('Model_name.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# initiate training\n",
    "history = model.fit(\n",
    "  train_images,\n",
    "  validation_data = validation_images,\n",
    "  epochs=epochs,\n",
    "  callbacks=[chkp]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting all hyper results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "# plotting Training and Validation Accuracy\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plotting the Training and Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "plt.savefig('testim.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_test(model):\n",
    "    '''\n",
    "    This functions tests the model on the test set and \n",
    "    automaticaly maps the resulting labels to a .csv file.\n",
    "    \n",
    "    '''\n",
    "    # getting labels\n",
    "    labels = (train_images.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "    # predicting on the test set\n",
    "    preds = model.predict(test_generator)\n",
    "    preds_cls_idx = preds.argmax(axis=-1)\n",
    "    predictions = [labels[k] for k in preds_cls_idx]\n",
    "\n",
    "    #m apping predictions and save as df\n",
    "    filenames=test_generator.filenames\n",
    "    filenames = [x.replace('test_set/', '') for x in filenames]\n",
    "    results=pd.DataFrame({\"img_name\":filenames,\n",
    "                          \"label\":predictions})\n",
    "    return results \n",
    "\n",
    "test_results_pr = predict_for_test(model)\n",
    "test_results = df_test_labels.merge(test_results_pr, how='left', on='img_name')\n",
    "test_results = test_results[['path', 'label_y']].rename(columns = {'label_y':'label', 'path':'img_name'})\n",
    "\n",
    "\n",
    "# writing pridictions to csv\n",
    "test_results.to_csv(\"sample_submission_model_J1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the prediction dist\n",
    "sns.countplot(x='label', data=test_results).set(title='Count per label')\n",
    "plt.show()\n",
    "# plt.savefig('model_1_label_dist.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
